{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\USER\\Downloads\\credit_card_fraud_detection\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First 5 rows of the dataset:\n",
       "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
       "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
       "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
       "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
       "\n",
       "[5 rows x 31 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First 5 rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Dataset summary:\n",
       "<class 'pandas.core.frame.DataFrame'>\n",
       "RangeIndex: 284807 entries, 0 to 284806\n",
       "Data columns (total 31 columns):\n",
       " #   Column  Non-Null Count   Dtype  \n",
       "---  ------  --------------   -----  \n",
       " 0   Time    284807 non-null  float64\n",
       " 1   V1      284807 non-null  float64\n",
       " 2   V2      284807 non-null  float64\n",
       " 3   V3      284807 non-null  float64\n",
       " 4   V4      284807 non-null  float64\n",
       " 5   V5      284807 non-null  float64\n",
       " 6   V6      284807 non-null  float64\n",
       " 7   V7      284807 non-null  float64\n",
       " 8   V8      284807 non-null  float64\n",
       " 9   V9      284807 non-null  float64\n",
       " 10  V10     284807 non-null  float64\n",
       " 11  V11     284807 non-null  float64\n",
       " 12  V12     284807 non-null  float64\n",
       " 13  V13     284807 non-null  float64\n",
       " 14  V14     284807 non-null  float64\n",
       " 15  V15     284807 non-null  float64\n",
       " 16  V16     284807 non-null  float64\n",
       " 17  V17     284807 non-null  float64\n",
       " 18  V18     284807 non-null  float64\n",
       " 19  V19     284807 non-null  float64\n",
       " 20  V20     284807 non-null  float64\n",
       " 21  V21     284807 non-null  float64\n",
       " 22  V22     284807 non-null  float64\n",
       " 23  V23     284807 non-null  float64\n",
       " 24  V24     284807 non-null  float64\n",
       " 25  V25     284807 non-null  float64\n",
       " 26  V26     284807 non-null  float64\n",
       " 27  V27     284807 non-null  float64\n",
       " 28  V28     284807 non-null  float64\n",
       " 29  Amount  284807 non-null  float64\n",
       " 30  Class   284807 non-null  int64  \n",
       "dtypes: float64(30), int64(1)\n",
       "memory usage: 67.4 MB\n",
       "None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nDataset summary:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Missing values in each column:\n",
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Class distribution:\n",
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = data['Class'].value_counts()\n",
    "print(\"\\nClass distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values, palette=\"viridis\")\n",
    "plt.title('Class Distribution (0 = Genuine, 1 = Fraudulent)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic statistics for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Basic statistics:\n",
       "                Time            V1  ...         Amount          Class\n",
       "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
       "mean    94813.859575  1.168375e-15  ...      88.349619       0.001727\n",
       "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
       "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
       "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
       "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
       "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
       "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
       "\n",
       "[8 rows x 31 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nBasic statistics:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate majority and minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = data[data['Class'] == 0]\n",
    "df_minority = data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),  # Match the number of majority class samples\n",
    "                                 random_state=42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the upsampled minority class with the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the upsampled minority class with the majority class\n",
    "data_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check new class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Balanced class distribution:\n",
       "Class\n",
       "0    284315\n",
       "1    284315\n",
       "Name: count, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nBalanced class distribution:\")\n",
    "print(data_balanced['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data_balanced.drop('Class', axis=1) # Features (drop the 'Class' column)\n",
    "y = data_balanced['Class'] # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Logistic Regression model with class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', random_state=42)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Prediction on Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation - Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification Report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "     Genuine       0.92      0.98      0.95     56746\n",
       "  Fraudulent       0.98      0.92      0.95     56980\n",
       "\n",
       "    accuracy                           0.95    113726\n",
       "   macro avg       0.95      0.95      0.95    113726\n",
       "weighted avg       0.95      0.95      0.95    113726\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred, target_names=['Genuine', 'Fraudulent'])\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Explanation:\n",
    "# The classification report includes the precision, recall, f1-score, and support for each class.\n",
    "# - Precision: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "# - Recall: The ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "# - F1-Score: The weighted average of Precision and Recall.\n",
    "# - Support: The number of actual occurrences of the class in the specified dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix:\n",
       "[[55503  1243]\n",
       " [ 4521 52459]]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Genuine', 'Fraudulent'], yticklabels=['Genuine', 'Fraudulent'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Perform Prediction on Test Sets\n",
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the classification report\n",
    "rf_report = classification_report(y_test, y_pred_rf, target_names=['Genuine', 'Fraudulent'])\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(rf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the confusion matrix\n",
    "rf_conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(rf_conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(rf_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Genuine', 'Fraudulent'], yticklabels=['Genuine', 'Fraudulent'])\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
